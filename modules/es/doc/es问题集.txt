-----------------------------------es问题集--------------------------------
1，es集群重启后，出现分片未分配的情况 unassigned shards 情况
a，使用es的cat API分析未分配的分片信息及未分配的原因
curl -XGET localhost:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason| grep UNASSIGNED
b，查看es节点数据存储磁盘已使用容量，如果超过cluster.routing.allocation.disk.watermark.low闸值或对应比例，es不会将分片分给此节点。
  此种情况下，需要对数据磁盘扩容，才能解决 unassigned shards情况。
c，es主节点不会将主分片和副本分片分配至同一个节点，同样，也不会将两个副本节点分配到同一个节点，
  所以当没有足够的节点分配分片时，会出现未分配的状态。检查节点数和副本数的关系，应该为N>=R+1 （其中N为节点数，R为副本数量）
  如果节点数不够，需要增加节点数 或减少副本数，使关系成立，才能避免这种情况发生。
d，强制重新分配集群中的UNASSIGEMED Shards
curl -XPOST localhost:9200/_cluster/reroute?retry_failed=true
e，手动更改集群中分片的分配
curl -XPOST localhost:9200/_cluster/reroute -d '{
    "commands" : [ {
        "allocate" : {
        "index" : "xxx",
        "shard" : 1,
        "node" : "node1",
        "allow_primary": true }
    } ]
}'
f，检查是否集群中某索引的分片数据已不存在，这中情况下处理方式
  1,恢复存有分片的源节点，加入到集群中(集群关闭自分配的前提下)
  2,使用Reroute API强制重分配分片
  curl -XPOST localhost:9200/_cluster/reroute -d '{
      "commands" :[ {
          "allocate_empty_primary" :{
          "index" :"xxx",
          "shard" : 0,
          "node":"<NODE_NAME>",
          "accept_data_loss": "true" }
      } ]
  }'
  3,从原始数据重建索引或者从备份快照中恢复
g，如果某个node突然挂掉了导致某些shard是unassigned的，这时如果cluster.routing.allocation.enable:none
   那么即使cluster.routing.rebalance.enable:all,这些unassigned的shard也不会被分配到其他节点，因为最根本的shard分配操作被禁止了。
   如果这时设置为cluster.routing.rebalance.enable: none，cluster.routing.allocation.enable: all
   那么对应的unassigned的shard会被分配到其他节点上面。重启挂掉的node(如果node上面没有数据)，那么该node上面的shard数量会一直是0，
   因为rebalance被关闭了。当重新设置cluster.routing.rebalance.enable: all的时候，才会将部分shard迁移到新启动的node上面。
   rebalance的功能需要依赖allocation功能的开启，allocation没开启就不能进行rebalance操作的（手动的relocation也不能进行），
   allocation还会限制shard丢失之后的shard重新分配。
h，也有可能多版本不兼容问题，导致分片未分配

2，es更数据时报VersionConflictEngineException
es更新数据时偶尔会报VersionConflictEngineException，经过分析是因为系统存在多个应用同时更新数据的场景。
es是乐观锁数据更新，通过版本号控制。而我们的数据更新场景为部分数据更新，es会进行数据反查然后进行更新，反查和更新之间存在其他线程更新数据的情况，
因此当前数据版本号和反查得到的版本号不一致，会抛出异常
可以通过设置request.setRetryOnConflict(10); //版本号冲突时会重试10次，来解决问题。

3，es分片不均匀，集群负载不均衡
es集群共3节点，索引主分片集中在2个节点，另1节点全是副本，此节点的资源就没有利用起来，只是备份数据，而读写压力都在其他2节点上，各节点负载不均衡
1，手动移动分片
curl -XPOST http://localhost:9200/_cluster/reroute -d '{
  "commands":[{
    "move":{
      "index":"indexName",
      "shard":0,
      "from_node":"node1",
      "to_node":"node2"
    }
  }]
}'

4，es写入数据时报错EsRejectedExecutionException[rejected execution of org.elasticsearch.transport.netty.
MessageChannelHandler$RequestHandler@123456 on EsThreadPoolExecutor[index, queue capacity = 200
这是写入流量超出了es服务器index的吞吐能力，索引线程池队列满了而报错，
要么降低写入流量，要么增加索引线程池的吞吐能力，比如队列长度，线程池大小不建议调整(默认已经是比较优的设置了)
比如8核机器上es 索引线程池配置
threadpool:
    index:
        type: fixed
        size: 8
        queue: 1000                        ###默认200
        reject_policy: caller              ###默认abort

---------------------------------------------------------------------------