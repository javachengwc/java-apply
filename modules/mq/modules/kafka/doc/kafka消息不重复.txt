kafka消息不重复
1，打开Producer消息的幂等性，能保证生产消息不重复。
   如果设置了重试机制，比如因网络抖动导致超时，但实际broker已经收到消息，但发送方会重新发送消息。
   这会导致消息发送重复。
2，Consumer端消息重复消费的根本原因在于：已经消费了数据，但是offset没有成功提交。
   大概原因包括（其中很大一部分原因在于发生了再均衡）：
   a，消费者宕机、重启等。导致消息已经消费但是没有提交offset。服务故障重启或恢复后会拉取相同一批数据。
   b，消费者使用自动提交offset，但当还没有提交的时候，有新的消费者加入或者移除，发生了rebalance（再平衡）。
      再次消费的时候，消费者会根据提交的偏移量来，于是重复消费了数据。
   c，消息处理耗时，或者消费者拉取的消息量太多，处理耗时，
      超过了max.poll.interval.ms的配置时间，导致认为当前消费者已经死掉，触发再均衡。
   d，其他
   所以，Consumer端要保证消费消息不重复，需要消费做幂等处理。

rebalance是kafka认为消费者已经离线或者挂掉或则有新的消费者加入，就会触发rebalance把消息分配给新的消费者。
导致rebalance的原因可能有：
   a，消费后的数据，当offset还没有提交时，partition就断开连接。
      比如，消费的数据处理很耗时，导致超过了Kafka的session timeout时间（0.10.x版本默认是30秒），
      那么就会reblance重平衡，此时有一定几率offset没提交，会导致重平衡后重复消费。
   b，并发很大，可能在规定的时间（session.time.out默认30s）内没有消费完，
      就会可能导致reblance重平衡，导致一部分offset自动提交失败，然后重平衡后重复消费。
   c，当消费者消费的速度很慢的时候，可能在一个session周期内还未完成，导致心跳机制检测报告出问题。
   d，强行kill线程，导致消费后的数据，offset没有提交（消费系统宕机、重启等）。

影响rebalance触发的参数
1，spring.kafka.properties.session.timeout.ms  当broker多久没有收到consumer的心跳请求后就触发rebalance，默认值是10s。
在0.10.1.0之前的版本中，由于心跳请求是在poll()拉取消息的方法中执行的，
因此如果当前批次处理消息耗时太长，就会导致consumer没有机会按时发送心跳，broker认为消费者已死，触发rebalance。
在0.10.1.0或更新的版本中解决了这个问题，心跳请求会在单独的线程中发送，因此就不会出现因为消息处理过长而发不出心跳的问题了。
而每次发送心跳请求的时间 spring.kafka.properties.heartbeat.interval.ms = 3000（默认3s）

2，spring.kafka.properties.max.poll.interval.ms  两次poll()之间的最大间隔，默认值为5分钟。
超过这个间隔同样会触发rebalance。在多数情况下这个参数是导致rebalance消息重复的关键，
即业务处理消息耗时太长，导致一直没有commit确认收到的消息，然后超过了消费者设置的最大拉取时间。
能否在5分钟内处理完还取决于每次拉取了多少条消息，如果一次拿到上万条消息，5分钟也未必处理完。
有也可能是某个消费者节点线程阻塞，超过了最大拉取时间。

3，spring.kafka.consumer.max.poll.records  poll()方法最多可以返回多少条消息，默认值为500。
如果消息处理耗时比较长，可能很难保证能够在5分钟内处理完500条消息，如果无法按时消费完成的话就会触发rebalance,
然后这批消息会被分配到另一个消费者中，如果还是处理不完，又会触发rebalance,
这样这批消息就永远也处理不完，而且一直在重复处理。



